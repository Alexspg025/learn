#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{url} 
\usepackage{slashed}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "times" "default"
\font_sans "helvet" "default"
\font_typewriter "cmtt" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\listings_params "basicstyle={\ttfamily},basewidth={0.45em}"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Language Learning Diary - Part Eight
\end_layout

\begin_layout Date
Sept 2022 - present
\end_layout

\begin_layout Author
Linas Vep≈°tas
\end_layout

\begin_layout Abstract
The language-learning effort involves research and software development
 to implement the ideas concerning unsupervised learning of grammar, syntax
 and semantics from corpora.
 This document contains supplementary notes and a loosely-organized semi-chronol
ogical diary of results.
 The notes here might not always makes sense; they are a short-hand for
 my own benefit, rather than aimed at you, dear reader!
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Part Eight of the diary is a collection of notes from the literature, collected
 here as a handy reference (because adequate articles on some of these ideas
 do not yet exist).
 
\end_layout

\begin_layout Section*
Summary Conclusions
\end_layout

\begin_layout Standard
A summary of what is found in this part of the diary:
\end_layout

\begin_layout Itemize
No summary yet.
\end_layout

\begin_layout Section*
Mapping Paramters to Bipolar Hypervectors
\end_layout

\begin_layout Standard
A bipolar hypervector is a vector in a 
\begin_inset Formula $D$
\end_inset

-dimensional space having values in the set 
\begin_inset Formula $\mathbb{Z}_{2}=\left\{ -1,1\right\} $
\end_inset

; that is, a vector in 
\begin_inset Formula $\left\{ -1,1\right\} ^{D}.$
\end_inset

 Every hypervector corresponds to a vertex of a hypercube centered at the
 origin of a 
\begin_inset Formula $D$
\end_inset

-dimensional space.
 Bipolar hypervectors have the interestng property that, for 
\begin_inset Formula $D$
\end_inset

 even, given any (random) vector 
\begin_inset Formula $v$
\end_inset

, if one flips half the bits to get a vector 
\begin_inset Formula $w$
\end_inset

, then 
\begin_inset Formula $v$
\end_inset

 and 
\begin_inset Formula $w$
\end_inset

 are orthogonal!
\end_layout

\begin_layout Standard
This interesting property can be used to map point sequences (
\begin_inset Quotes eld
\end_inset

curves
\begin_inset Quotes erd
\end_inset

) to sequences of bipolar hypervectors such that the endpoints of the point
 sequence are orthogonal, and intermediate points have increasingly larger
 cosine distances.
 Geometrically, this maps the point sequence to a sequence of corners on
 the hypercube that are increasingly distant from the starting point.
 of point sequences to hypervectors
\end_layout

\begin_layout Standard
This map is a homomorphism that preserves the metric on the point sequence.
 This metric property can then be deployed to simplify classification problems,
 by mapping the space to be classified to vector arithmetic and cosine distances.
 These two ideas are developed below.
\end_layout

\begin_layout Subsection*
Metric properties
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left[p_{0},\cdots,p_{N}\right]$
\end_inset

 be a totally ordered sequence of points.
 The total order is just 
\begin_inset Formula $p_{i}<p_{j}$
\end_inset

 for 
\begin_inset Formula $i<j$
\end_inset

 for integer index 
\begin_inset Formula $i,j$
\end_inset

.
 This order can be metrizied with a metric 
\begin_inset Formula $g$
\end_inset

 such that 
\begin_inset Formula $g\left(p_{i},p_{j}\right)=\left|i-j\right|/N$
\end_inset

.
 The metric is normalized written so that the maximum distance is 1.
 Pick a dimension 
\begin_inset Formula $D>2N$
\end_inset

 and conventionally 
\begin_inset Formula $D\gg2N$
\end_inset

 and an arbitrary initial (random) vector 
\begin_inset Formula $v_{0}$
\end_inset

 that will correspond to 
\begin_inset Formula $p_{0}$
\end_inset

.
 Generate a sequence of bipolar hypervectors 
\begin_inset Formula $v_{k}$
\end_inset

 as follows.
 Given 
\begin_inset Formula $v_{i}$
\end_inset

, select (randomly) 
\begin_inset Formula $D/2N$
\end_inset

 bits that have not been selected before, and flip them, to obtain 
\begin_inset Formula $v_{i+1}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The above generates a sequece of (bipolar hyperdimensional) vectors with
 the following properties.
 The dot product is 
\begin_inset Formula 
\[
v_{k}\cdot v_{k}=D
\]

\end_inset

For neighboring points, the dot product is 
\begin_inset Formula 
\[
v_{k}\cdot v_{k+1}=D\left(1-\frac{1}{N}\right)
\]

\end_inset

because these differ in 
\begin_inset Formula $D/2N$
\end_inset

 bit locations.
 (The Hamming distance is 
\begin_inset Formula $D/2N$
\end_inset

; so 
\begin_inset Formula $D/2N$
\end_inset

 bit positions that are 
\begin_inset Formula $+$
\end_inset

 are replaced by 
\begin_inset Formula $-$
\end_inset

, and so that total sum decreases by 
\begin_inset Formula $N$
\end_inset

.)
\end_layout

\begin_layout Standard
In general, the Hamming distance between 
\begin_inset Formula $v_{k}$
\end_inset

 and 
\begin_inset Formula $v_{k+n}$
\end_inset

 is 
\begin_inset Formula $nD/2N$
\end_inset

 and so the dot product is
\begin_inset Formula 
\[
v_{k}\cdot v_{k+n}=D\left(1-\frac{n}{N}\right)
\]

\end_inset

or equivalently
\begin_inset Formula 
\[
v_{i}\cdot v_{j}=D\left(1-\frac{\left|i-j\right|}{N}\right)
\]

\end_inset

so that 
\begin_inset Formula 
\[
v_{0}\cdot v_{N}=0
\]

\end_inset

are orthogonal.
 The Hamming distance between orthogonal vectors is necessarily 
\begin_inset Formula $D/2$
\end_inset

.
\end_layout

\begin_layout Standard
Normalizing by 
\begin_inset Formula $D$
\end_inset

 and subtracting from 1 reproduces the original metric on the point sequence:
 i.e.
 
\begin_inset Formula 
\[
g\left(p_{i},p_{j}\right)=\frac{\left|i-j\right|}{N}=1-\frac{v_{i}\cdot v_{j}}{D}
\]

\end_inset


\end_layout

\begin_layout Standard
Some notes:
\end_layout

\begin_layout Itemize
Almost all random vectors are orthogonal to one another (or nearly so).
 This follows from binomial coefficents being approximations for Gaussians.
 There are 
\begin_inset Formula 
\[
{D \choose D/2}=\frac{D!}{\left(D/2\right)!^{2}}\approx\sqrt{2/\pi D}\,2^{D}
\]

\end_inset

orthogonal vectors, which follows from Stirling's law 
\begin_inset Formula $n!\approx\sqrt{2\pi n}e^{-n}n^{n}$
\end_inset

.
 There are 
\begin_inset Formula 
\[
{D \choose \frac{D}{2}+1}=\frac{D!}{\left(\frac{D}{2}-1\right)!\left(\frac{D}{2}+1\right)!}\approx\sqrt{2/\pi D}\,2^{D}xxx
\]

\end_inset

almost orthogonal vectors, that differ by one bit.
 More generally, for 
\begin_inset Formula $n\ll D$
\end_inset

 there are 
\begin_inset Formula 
\[
{D \choose \frac{D}{2}+n}=\frac{D!}{\left(\frac{D}{2}-n\right)!\left(\frac{D}{2}+n\right)!}\approx\sqrt{2/\pi D}\,2^{Dxxx}xxx
\]

\end_inset

vectors that differ by 
\begin_inset Formula $n$
\end_inset

 bits.
\end_layout

\begin_layout Itemize
Given two corners on a hypercube differeing by 
\begin_inset Formula $d$
\end_inset

 bits, there are 
\begin_inset Formula $2^{d}$
\end_inset

 shortest paths between them.
\end_layout

\begin_layout Itemize
The midway points on such paths can have larger Jaccard (Hamming) distances
 to each other, than to either endpoint.
 In fact, this will almost always be the case.
\end_layout

\begin_layout Itemize
If the vectors are normalized, they can be seen to live on the surface of
 a sphere (of the same dimension).
\end_layout

\begin_layout Standard
Of course, all this machination is pointless for one-dimensional point sequences.
 So ...
 for the more complex case.
\end_layout

\begin_layout Subsection*
Dimensional Oxidation
\end_layout

\begin_layout Standard
In chemistry, oxidation is the opposite of reduction.
 If dimensional reduction is the reduction of the number of dimensions to
 describe a dataset, then playing on this, dimensional oxidation is the
 act of increasing dimensions.
\end_layout

\begin_layout Standard
One conventional machine learning problem is the classification of regions
 of some 
\begin_inset Formula $M$
\end_inset

-dimensional space features.
 That is, there are a set of real-valued features 
\begin_inset Formula $f_{m}\in\mathbb{R}$
\end_inset

 for 
\begin_inset Formula $1\le m\le M$
\end_inset

.
 These are presumed to be bounded, so that 
\begin_inset Formula $f_{m}^{\mathrm{min}}\le f_{m}\le f_{m}^{\mathrm{max}}$
\end_inset

 so that these can be normalized to the unit cube 
\begin_inset Formula $\left[0,1\right]^{M}$
\end_inset

 by writing 
\begin_inset Formula 
\[
x_{m}=\frac{f_{m}-f_{m}^{\mathrm{min}}}{f_{m}^{\mathrm{max}}-f_{m}^{\mathrm{min}}}
\]

\end_inset

Each unit interval may be digitized (partitioned) into 
\begin_inset Formula $N+1$
\end_inset

 distinct subintervals.
 This partitioning 
\begin_inset Formula $\left[p_{0},\cdots,p_{N}\right]$
\end_inset

 then provides a totally ordered points sequence that can be mapped to bipolar
 hypervectors.
 A given point 
\begin_inset Formula $x\in\left[0,1\right]^{M}$
\end_inset

 is thus mapped to 
\begin_inset Formula $M$
\end_inset

 vectors 
\begin_inset Formula $v_{m}$
\end_inset

.
 Summing these provides a mapping of the unit cube to 
\begin_inset Formula $\mathbb{Z}^{D}$
\end_inset

:
\begin_inset Formula 
\[
w=w\left(x\right)=\sum_{m}v_{m}
\]

\end_inset

Since the sum is bounded between 
\begin_inset Formula $-M$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 in each direction, this vector lies on the hypercube lattice 
\begin_inset Formula $\left(2M\right)^{D}$
\end_inset

.
\end_layout

\begin_layout Standard
If these vectors are normalized to unit length, then they live on the surface
 of the hypersphere 
\begin_inset Formula $S_{D-1}$
\end_inset

.
 In general, these points are not random, ly distributed on the hypersphere.
 In a narrow sense, we can offer a theorm: the points are randomly distributed
 on the hypersphere if and only if they are randomly distributed in the
 unit cube 
\begin_inset Formula $\left[0,1\right]^{M}$
\end_inset

.
 However, in a broader sense, when 
\begin_inset Formula $N\ll D$
\end_inset

, points are increasingly scattered on the unit sphere, becoming increasingly
 uniformly distributed.
 This is effectively because the start and end points of the unit interval
 are mapped to random hypervectors.
 (This follows(?) because random hypervectors have a binomial bit distribution,
 and for large 
\begin_inset Formula $D$
\end_inset

, the binomial distribution approaches the Gaussian).
\end_layout

\begin_layout Standard
So again, we seem to approach the case of a Gaussian Orthogonal Ensemble.
 Kind of...
\end_layout

\begin_layout Section*
The End
\end_layout

\begin_layout Standard
This is the end of Part Eight of the diary.
 
\end_layout

\end_body
\end_document
