
Title page:
* Hi, My name is linas Vepstas, you can call me Linas.
* I'm here to talk about the automated, unsupervised learning
  of explainable, comprehendable patterns in language, 
  and in a general setting that includes audio and video,
  or anything -- the noosphere.

Slide 1:
* I'm  going to start by making some outrageous claims.
* I'm going to claim that the system being presented here is capable of
  solving the famous Frame Problem, the Symol Grounding Problem.
* That common-sense reasoning can be learned.
* Not only are these claims the holy grail of AGI, which is why they are
  outrageous,
* But I will present an aglortihm that is not particularly complicated.
* It consists of some fairly well-known parts that many others have
  fooled with over the decades.
* Its not in uncharted territory.

* In this sense, most of what I will say has been said before.
* It might even seem obvious, or simplisitic to you, or even naive.
* I'd like to ask for your attention none-the-less, as you may find 
  the particular combination here surprising and unusual.
* Bear with me. I'll start out simple.

Everything in the universe is a graph
* This is the universe not just of physical stars and planets,
  but also the universe of thoughts and concepts, the noosphere.
* Sparse graphs are necessarily labeled, as otherwise there is no
  way of talking about the things in the graph.
* The edges are necessarily labelled by the vertexes at thier
  end-points.

Graphs are decomposable
* This should be obvious, but is rarely mentioned in graph theory.
* You can gut an edge to get two half-edges.
* After cutting the egde, you need to label the cut ends so that
  you know how to join them again.
* The metaphor I will us repeatedly is that of the jigsaw puzzle-piece
  connector.
* Jigsaw puzzle pieces are designed so that the mating 
  of the pieces is forced. 
* When you cut an edge, attach a connector to it.
* In this example, polarity is indeterminate; flip a coin.

* In the gran scheme of things, you will discover that connectors
  can be multi-polar, multi-sexual.
* This is perhaps politically controversial, but biologists have found
  fungi with 43 different types of sex.
* Some of these can mate, and produce viable offsprint, and some cannot.
  Its quite strange.

* I've drawn a picture of a telescope jigsaw-puzzle piece, with
  connectors for looking at the sun and the moon.
* There are other things that can se the sun and the moon: eyes and
  lenses.  They have the same jigsaw shape.
* These shapes define the syntax of the graph..
* The syntax is exactly that collection of shapes that allow connections
  to occur.

* This might not be the defnition of syntax that you are comfortable
  with, or that you have learned. 
* It is, however, entirely equivalent to the more conventional
  defintions you may know.
* This is not a particularly deep claim, it's fairly well-known and
  well-understood, I'm sorry only in not having a good reference for it
  at my fingertips.

Graphs are Compositional
* This is so basic, so obvious that
  We are like fish in water, we are not aware of the water.
  That's why I have to say these things out loud.
* At the top of this chart, I've drawn a conventional defintion of a
  term algebra.
* The jigsaw connectors generalize the concepts of term algebras
  to not be not just DAG's, but diected/undirected graphs in general.
* Type theory types may themselves decomposable, may have structure.

Slide physics:
* Anything tensorial.
* Compostion is like contracting tensor indexes.
* Coecke actually says you can parse natural language in linear time
  with quantum algorithms.

Chemistry Biology
 * A chemical reaction has inputs and outputs.
 * These are the "connectors", the jigsaw puzzle pieces.
 * The algorithmic botany work is beautiful and stunning.

Link Grammar:
* The diagram is taken from the original 1991 LG paper.
  It explicitly uses jigsaw-puzzle pieces.
* The LG type system is oversimplified, here. The type matching system
  is more complex, and polarity +/- indicate left-right.

Vision:
* Polarity direction is arbitrary, here, but there are differrent
  kinds of connectors - up-down vs shape vs color.

Audio:
* This is a whale song from NOAA.
* The diagram is a structural representation of the first 10 seconds
  of the chart, where you can see (plainly see) chirps, every two
  seconds.
* Make chirp/tweet sound

Lexical attraction
* Diagram is from Yuret's thesis

Lexical entries
* ampersand resembles "linear logic"
* Tensorial notation popular in quantum-influenced thinking
* d is for disjunct because the connector sequences are disjoined.
* The plus sign is a lie: its actually a menu-choice,
  to build once sentence you must pick one.
* hat-e is a unit basis vector

Similarity scores
* Problem with assuming Euclidean space is that taking orthogonal
  projections can lead to negative probabilities. Its pathological.
* Experimental measurements show that cosine distance is low quality
* MI is well-behaved under Markov (affine) transformations.
* Star means sum over everything
* It's a weighted word probability.
* Its a feynmann diagram with a vacuum contribution!

Factorization
* When I call two different words "a noun", I am assigning them to a
  "grammatical class".
* All words in that grammatical class behave similarly.
* I am going from a specific matrix of (word-disjunct) pairs to
  a matrix of (grammatical class, syntactic structure) pairs.
* Neural nets can accurately capture the dense, interconnected central
  region, but they necessarily perform dimensional reduction on
  the sparse left and right factors. By erasing the sparse factors,
  neural nets become no longer interpretable.

Compositionality
* Assembled portions of a jigsaw puzzle are just like a single jigsaw
  puzzle piece: an area with a bunch of unconnected connectors.

Something from Nothing
* We got lucky with the words
* We need to find processors that convert input intto "words".
* Extremely high dimensional .. billions!

Symbol grounding problem
* This is interpretability.
* What is a "whistle"? Oh, it is a specific filter sequence
* "I know a whistle when I hear it" but how can I explain it?

* The frame problem asks: what parts of the environment are
  important for making deciisions?
* Answer: those parts of the environment that have been filtered
  out by the currrent active filters.
* But what are those?
* Answer: they were learned, by applying mutual information to
  extract similarity, and then factorize/generalize into common
  situations we find ourselves in.

Common Sense Reasoning
* Olde-school AI work on reasoning harks to the foundations of
  mathematical logic developed in the first half of the 20th century.
* The trope is that common sense is somehow like mathematical logic
* "The rational actor" of the enlightenment, of economics.
  (Its not)
* Never explain a joke.
* But this is important.
* This is funny precisely because its logic that correct, but
  fails the meta problem of why we went to the doctor in the first
  place.
* The common-sense reasoning context is that this is taking place in a
  doctors office, which drags in the frame (the frame problem) of
  everything that doctors do, which include curing ailments.
  (Frames are like the lexical functions of MTT. They tell you how to
  navigate the network of relations.)
* If we can learn lexical functions, then we can learn common-sense
  behavior patterns, and common-sense reasoning.
* We can learn the network of what happens in a doctors office, and
  how to navigate that network. (The same way we navigate lexical
  functions).
* We can determine that the advice "don't do that" fails to match the
  "rational" expectations of what happens in a doctors office.
* But what are the "rational expectations" of what happens in a doctors
  office? it is that learned network.
* That's the joke, explained.
* We can learn the rules of reasoning; they are not God-given (aka
  hard-coded by some programmer.)

Conclusions
* I skipped over experimental results. There are a lot of them.
  They come out of the blue - like the gaussian distribution.
  I have no clue why. Nor do any search engines.  There is
  effectively no published theory on anything I talked about today.
* Its a HUGE vaccum, and its also an opportunity for any student who
  want to make a mark on the AGI world.

----

is this a gaussian unitary ensemble?

Extra material:
the definition of syntax here is the same as the conventinoal defn of
syntax.
